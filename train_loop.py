# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k3UOqytvyHSaycqgWebe6THrzaKemoEc
"""

import matplotlib.pyplot as plt
from torchvision.transforms import functional
from PIL import Image
import torch
import os
import torch.nn as nn
import time as time
import numpy as np
from IPython import display
from skimage.color import lab2rgb

##################################################

def generate_images(model, input_val, target_val, num, device):
  input_val_l = input_val.to(device)
  target_val_ab = target_val.to(device)

  model.eval()
  with torch.no_grad():
    test_input = torch.unsqueeze(input_val_l,0).to(device)
    prediction = model(test_input).detach()

  val_l = (input_val_l + 1) * 50
  val_ab = target_val_ab * 128
  val_Lab = torch.cat([val_l, val_ab], dim=0).permute(1,2,0).cpu().numpy()
  val_rgb= lab2rgb(val_Lab)
 
  prediction_ab = torch.squeeze(prediction,0) * 128
  prediction_Lab = torch.cat([val_l, prediction_ab], dim=0).permute(1,2,0).cpu().numpy()
  prediction_rgb= lab2rgb(prediction_Lab)
  plt.figure(figsize=(15, 15))
  display_list = [val_l, val_rgb, prediction_rgb]
  title = ['Input Image', 'Ground Truth', 'colorized Image']

  for i in range(3):
      plt.subplot(1, 3, i+1)
      plt.title(title[i])
      image = display_list[i]
      if i==0:
        plt.imshow(torch.squeeze(image,0).cpu(), cmap = 'gray')
      else:
        plt.imshow(image)
      plt.axis('off')
  script_dir = os.path.dirname('./')
  results_dir = os.path.join(script_dir, 'image_folder/')
  if not os.path.isdir(results_dir):
      os.makedirs(results_dir)


  plt.savefig(results_dir +'image_{:04d}.png'.format(num))
  plt.show()
  model.train()

####################################################

cross_entropy = nn.BCEWithLogitsLoss()
l1loss = nn.L1Loss()
LAMBDA = 100

def generator_loss(disc_generated_output, gen_output, target, device):
    
    gan_loss = cross_entropy(disc_generated_output, torch.ones_like(disc_generated_output, device=device))

    l1_loss = l1loss(gen_output, target)

    total_gen_loss = gan_loss + (LAMBDA * l1_loss)

    return total_gen_loss, gan_loss, l1_loss

def discriminator_loss(disc_real_output, disc_generated_output,device):
    
    real_loss = cross_entropy(disc_real_output, torch.ones_like(disc_real_output, device=device))
    generated_loss = cross_entropy(disc_generated_output, torch.zeros_like(disc_generated_output, device=device))

    total_disc_loss = real_loss + generated_loss

    return total_disc_loss

######################################################

def train_step(input_image, target, generator, discriminator, dis_opt, gen_opt, device):
    
    gen_output = generator(input_image)
    for param in discriminator.parameters():
      param.requires_grad = True
    
    dis_opt.zero_grad()

    disc_generated_output = discriminator(input_image, gen_output.detach())
    disc_real_output = discriminator(input_image, target)

    dis_loss = discriminator_loss(disc_real_output, disc_generated_output, device)

    
    dis_loss.backward()
    dis_opt.step()

    for param in discriminator.parameters():
      param.requires_grad = False
    gen_opt.zero_grad()
    
    disc_generated_output = discriminator(input_image, gen_output)

    gen_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target, device)
    
    gen_loss.backward()
    gen_opt.step()

    return gen_loss, dis_loss

def valid_step(input_image, target, generator, discriminator, device):

  generator.eval()
  discriminator.eval()
  with torch.no_grad():

    gen_output = generator(input_image)
    disc_generated_output = discriminator(input_image, gen_output.detach())
    disc_real_output = discriminator(input_image, target)

    gen_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target, device)
    dis_loss = discriminator_loss(disc_real_output, disc_generated_output, device)
  generator.train()
  discriminator.train()
  return gen_loss, dis_loss

##################################################################

def train(data_train, data_val, val_visual, epochs, generator, discriminator,dis_opt, gen_opt, device):
  gloss_train = []
  dloss_train = []

  gloss_val = []
  dloss_val = []
  
  start_koli = time.time()
  for epoch in range(epochs):
    start = time.time()

    gen_losses_t = []
    disc_losses_t = []

    gen_losses_v = []
    disc_losses_v = []

    for input_image,target  in data_train:
        input_image = input_image.to(device)
        target = target.to(device)
        gen_loss_t, disc_loss_t = train_step(input_image, target, generator, discriminator, dis_opt, gen_opt, device=device)
        gen_losses_t.append(gen_loss_t.detach().cpu())
        disc_losses_t.append(disc_loss_t.detach().cpu())

    for input_image,target  in data_val:
        input_image = input_image.to(device)
        target = target.to(device)
        gen_loss_v, disc_loss_v = valid_step(input_image, target, generator, discriminator, device=device)
        gen_losses_v.append(gen_loss_v.detach().cpu())
        disc_losses_v.append(disc_loss_v.detach().cpu())

    gloss_train.append(np.mean(gen_losses_t))
    dloss_train.append(np.mean(disc_losses_t))

    gloss_val.append(np.mean(gen_losses_v))
    dloss_val.append(np.mean(disc_losses_v))    

    #Produce images
    #display.clear_output(wait=True)
    if epoch%5 == 0:
      generate_images(generator, val_visual[0][0], val_visual[0][1], epoch,device)
      print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

    

  # Generate after the final epoch
  #display.clear_output(wait=True)
  generate_images(generator, val_visual[0][0], val_visual[0][1], epoch,device)
  print ('Total runtime for {} epoches is {} sec'.format(epoch + 1, time.time()-start_koli))
  total_time = time.time()-start_koli 
  torch.save({
            'epoch': epoch,
            'generator_state_dict': generator.state_dict(),
            'discriminator_state_dict': discriminator.state_dict(),

            # 'gen_opt_state_dict': dis_opt.state_dict(),
            # 'dis_opt_state_dict': gen_opt.state_dict(),

            'gloss_train': gloss_train,
            'dloss_train': dloss_train,

            'gloss_val': gloss_val,
            'dloss_val': dloss_val,
  
            
            'Total_time' : total_time

            
            }, 'model_orig.tar')
  
  return gloss_train, dloss_train , gloss_val, dloss_val
