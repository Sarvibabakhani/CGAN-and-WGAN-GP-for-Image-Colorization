# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k3UOqytvyHSaycqgWebe6THrzaKemoEc
"""

import torch
import torch.nn as nn

class downsample(nn.Module): 

  def __init__(self, input_cha, output_cha, size, apply_batchnorm=True):
    super().__init__()

    if apply_batchnorm:
      self.model = nn.Sequential(
          nn.Conv2d(input_cha, output_cha, size, bias=False, stride=2, padding=1),
          nn.BatchNorm2d((output_cha)),
          nn.LeakyReLU(0.2,True)
      )
    else:
      self.model = nn.Sequential(
          nn.Conv2d(input_cha, output_cha, size, bias=False, stride=2, padding=1),
          nn.LeakyReLU(0.2,True)
      )  

  def forward(self, x):
        y = self.model(x)
        return y


def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
        #nn.init.xavier_uniform_(m.weight.data)
    if classname.find('Linear') != -1:
        #nn.init.normal_(m.weight.data, 0.0, 0.02)
        nn.init.xavier_uniform_(m.weight.data)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)



class CGAN(nn.Module):

   def __init__(self):
        super().__init__()

        self.l1 = downsample(3, 64, 4, apply_batchnorm=False)  # (batch_size, 64, 128, 128)
        self.l2 = downsample(64, 128, 4)  # (batch_size, 128, 64, 64)
        self.l3 = downsample(128, 256, 4)  # (batch_size, 256, 32, 32)
        self.l4 = nn.ZeroPad2d(1) # (batch_size, 256, 34, 34)
        self.l5 =  nn.Sequential(
          nn.Conv2d(256, 512, 4, bias=False, stride=1),
          #nn.BatchNorm2d((512)),
          nn.LeakyReLU(inplace=False ) )  # (batch_size, 512, 31, 31)
        self.l6 = nn.ZeroPad2d(1)  # (batch_size, 512, 33, 33)
        self.l7 = nn.Conv2d(512, 1, 4, bias=False, stride=1) # (batch_size, 1, 30, 30)


   def forward(self,gray,input):

     l0 = torch.cat([gray, input], dim=1)
     l1 = self.l1(l0)
     l2 = self.l2(l1)
     l3 = self.l3(l2)
     l4 = self.l4(l3)
     l5 = self.l5(l4)
     l6 = self.l6(l5)
     output = self.l7(l6)

     return output